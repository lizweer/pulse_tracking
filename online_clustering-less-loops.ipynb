{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thunderfish.dataloader as dl\n",
    "import thunderfish.pulsetracker as pt\n",
    "import thunderfish.eventdetection as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters and functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peaks(x,y,peaksx,peaksy,c='k'):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(x,y,zorder=-1)\n",
    "    plt.scatter(starttime + peaksx/data.samplerate,peaksy,c=c)\n",
    "    plt.xlabel('time [s]')\n",
    "    plt.ylabel('signal')\n",
    "    \n",
    "def plot_events_on_data(peaks, data):\n",
    "    \n",
    "    \"\"\"\n",
    "        plots the detected events onto the data timeseries. If the events are classified, the classes are plotted in different colors and the class -1 (not belonging to a cluster) is plotted in black\n",
    "    \"\"\"\n",
    "    plt.plot(range(len(data)),data, color = 'black')\n",
    "    if len(peaks)>3:\n",
    "        classlist =  np.array(peaks[3],dtype=np.int)\n",
    "        if len(peaks) > 4:\n",
    "            classlist = np.array(peaks[4],dtype=np.int)\n",
    "        cmap = plt.get_cmap('jet')\n",
    "        colors =cmap(np.linspace(0, 1.0, 3000)) #len(np.unique(classlist))))\n",
    "        np.random.seed(3)\n",
    "        np.random.shuffle(colors)\n",
    "        colors = [colors[cl] for cl in np.unique(classlist)]\n",
    "        for cl, color in zip(np.unique(classlist), colors):\n",
    "            if min(classlist) == 0 and cl == 0:\n",
    "                color = 'black'\n",
    "            if cl == -1:\n",
    "                color = 'black'\n",
    "            \n",
    "            peaksofclass = peaks[:,classlist == cl]\n",
    "            plt.plot(peaksofclass[0],peaksofclass[1], '.', color = color,   ms =20, label=cl)\n",
    "    else:\n",
    "        plt.scatter(peaks[0],peaks[1], color = 'red')\n",
    "    #plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of filepaths..\n",
    "text_file = open(\"leticia_filenames_sorted.txt\", \"r\")\n",
    "lines = text_file.read().split('\\n')\n",
    "i = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/dexter/' + lines[i][:-4] + '/' + lines[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dexter/31105L01F14/31105L01F14.WAV'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = 0\n",
    "endtime = 1000 #in seconds\n",
    "\n",
    "with dl.open_data(filepath, -1, 1.0) as data:\n",
    "    dt = 1/data.samplerate\n",
    "    # do something with the content of the file:\n",
    "    x = np.arange(starttime,endtime,dt)\n",
    "    y = data[starttime*data.samplerate:endtime*data.samplerate,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# online clustering step by step\n",
    "## 1. EOD detection\n",
    "Create a data structures with the locations and amplitudes of the EODs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import correlate\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# parameters for the analysis\n",
    "thresh = 0.1 # minimal threshold for peakdetection\n",
    "peakwidth = 25 # width of a peak and minimal distance between two EODs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk, tr = ed.detect_peaks(y, thresh)\n",
    "peaks = pt.makeeventlist(pk,tr,y,peakwidth)\n",
    "peakindices, peakx, peakh = pt.discardnearbyevents(peaks[0],peaks[1],peakwidth)\n",
    "peaks = np.transpose(peaks[:,peakindices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Online clustering\n",
    "create object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cluster_object(object):\n",
    "    def __init__(self,label,mean,features,peaknum):\n",
    "        self.label = label\n",
    "        self.mean = mean\n",
    "        # this should be a numpy array with at least 100 peaks?\n",
    "        self.features = features\n",
    "        self.idxs = np.zeros(peaknum)\n",
    "        self.y = np.zeros(peaknum)\n",
    "        \n",
    "    def predict_next_idx(self):\n",
    "        \n",
    "        np.nonzero(cluster.idxs)[0][-1]\n",
    "        \n",
    "        return np.max(self.idxs) + self.get_isi()\n",
    "    \n",
    "    def get_isi(self):\n",
    "        return np.mean(np.diff(self.idxs[np.nonzero(self.idxs)[0]][-4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(eod,cluster_mean,width):\n",
    "    \n",
    "    # don't just take max but take a peak of the cc\n",
    "    # this is to prevent shifting to the next peak in the sequence.\n",
    "    \n",
    "    cc = correlate(eod,cluster_mean,'same')\n",
    "    local_max_idx = argrelextrema(cc[width:-width], np.greater)[0] + width\n",
    "    diff = np.abs(local_max_idx - len(eod)/2)\n",
    "    if diff.size > 0:\n",
    "        offset = local_max_idx[np.argmin(diff)]\n",
    "    else:\n",
    "        offset = int(len(eod)/2)\n",
    "    return extract(eod,offset,width)\n",
    "    \n",
    "def extract(eod,offset,width):\n",
    "    return eod[offset-width:offset+width]\n",
    "\n",
    "def normalize(x):\n",
    "    #return x - np.min(x)\n",
    "    return (((x-np.min(x))/(np.max(x)-np.min(x))) - 0.5)*2\n",
    "\n",
    "def gen_cheb(n,x):\n",
    "    return(np.cos(n*np.arccos(x)))\n",
    "\n",
    "#cmap = plt.get_cmap('jet')    \n",
    "colorss = ['k','b','r']#cmap(np.linspace(0, 1.0, 3000)) #len(np.unique(classlist))))\n",
    "#np.random.seed(3)\n",
    "#np.random.shuffle(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liz/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/liz/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/liz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:179: RuntimeWarning: invalid value encountered in less\n",
      "/home/liz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:183: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "clusters = []\n",
    "deleted_clusters = []\n",
    "\n",
    "maxlabel = 1\n",
    "labels = np.zeros(len(peaks))\n",
    "\n",
    "# parameters\n",
    "cutwidth = peakwidth\n",
    "alignwidth = 150\n",
    "int_met = 'quadratic'\n",
    "eta = 0.1\n",
    "error_threshold = 0.1 #different thresholds are needed for different problems\n",
    "npol = 15\n",
    "nfeat = 7\n",
    "\n",
    "#decide on the plotting\n",
    "plot_steps = False\n",
    "plot_means = False\n",
    "plot_one_peak_step = False\n",
    "\n",
    "if plot_means == True:\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2,figsize=(10,5))\n",
    "\n",
    "for i,p in enumerate(peaks):\n",
    "    \n",
    "    if plot_steps == True:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2,figsize=(10,5))\n",
    "        #f, ax1 = plt.subplots(1, 1,figsize=(5,5))\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.axis(\"off\")\n",
    "    \n",
    "    # cut along peak to get the EOD shape\n",
    "    p_idx = int(p[0])\n",
    "    p_hight = p[2]\n",
    "    p_y = p[1]\n",
    "    \n",
    "    eod = y[p_idx-cutwidth:p_idx+cutwidth]\n",
    "    \n",
    "    #interpolate --> needed to properly align peaks\n",
    "    eod_func = interp1d(range(len(eod)), eod, int_met)\n",
    "    eod_ip = eod_func(np.arange(0,len(eod)-1,0.1))\n",
    "    \n",
    "    # align peaks with aligning peak\n",
    "    if len(clusters) > 0:\n",
    "        \n",
    "        current_clusters = []\n",
    "        \n",
    "        # I only want to use recent clusters, \n",
    "        # but somehow I also need to save all clusters for later\n",
    "        for c, cluster in enumerate(clusters):\n",
    "            # delete clusters that are too far away\n",
    "            if p_idx - np.max(cluster.idxs) < 2000000: #and np.count_nonzero(labels == cluster.label) < 3:\n",
    "                current_clusters.append(cluster)\n",
    "            else:\n",
    "                deleted_clusters.append(cluster)\n",
    "                \n",
    "        clusters = current_clusters\n",
    " \n",
    "        c_feats = np.zeros((len(clusters),nfeat+1))\n",
    "        \n",
    "        # ============== start analysis =================\n",
    "        for c,cluster in enumerate(clusters):\n",
    "            c_feats[c] = cluster.features\n",
    "            \n",
    "            if plot_steps == True:\n",
    "                ax1.plot(cluster.mean,c=colorss[int(cluster.label)],label='fish %i'%cluster.label,linewidth=3.0)\n",
    "                ax1.title.set_text('Normalized EODs')\n",
    "                ax2.plot(cluster.features,c=colorss[int(cluster.label)],label='fish %i'%cluster.label,linewidth=3.0)\n",
    "                ax2.title.set_text('Features')\n",
    "        aligned_eod = align(eod_ip, align_peak, alignwidth)\n",
    "        \n",
    "        # normalize\n",
    "        mean = normalize(aligned_eod)\n",
    "        \n",
    "        # extract features\n",
    "        cheb = np.polynomial.chebyshev.Chebyshev.fit(np.linspace(-1,1,\n",
    "            len(mean)), mean, npol)\n",
    "        \n",
    "        #append peak hight to features\n",
    "        features = np.append(cheb.coef[:nfeat], p_hight/2)\n",
    "        \n",
    "        if plot_one_peak_step == True:\n",
    "            \n",
    "            chebfit = np.zeros(len(mean))\n",
    "            t = np.linspace(0,len(mean)*dt*0.1*1000,len(mean))\n",
    "            \n",
    "            for n in range(npol+1):\n",
    "                f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4,figsize=(15,5))\n",
    "                \n",
    "                ax1.plot(t,mean,c='r',linewidth=3.0)\n",
    "                ax1.title.set_text('1. Normalized Peak')\n",
    "                \n",
    "                current_cheb = gen_cheb(n,np.linspace(-1,1,len(mean)))\n",
    "                chebfit = chebfit + cheb.coef[n]*current_cheb\n",
    "                \n",
    "                ax1.plot(t,chebfit, c='k',linestyle='--',linewidth=2.0)\n",
    "                ax1.set_xlabel('Time [ms]')\n",
    "\n",
    "                ax2.title.set_text('2. Fitting Chebyshev polinomial')\n",
    "                ax2.plot(t,current_cheb,c='k',linewidth=3.0)\n",
    "                ax2.set_xlabel(\"Time [ms]\")\n",
    "                \n",
    "                ax3.plot(cheb.coef,c='k')\n",
    "                ax3.plot(n, cheb.coef[n], '.',c='k', ms=20)\n",
    "                ax3.title.set_text('3. Chebyshev coefficients')\n",
    "                ax3.set_xlabel('Coefficient #')\n",
    "                \n",
    "                ax4.axis('off')\n",
    "                f.savefig('a%i.png'%n)\n",
    "            \n",
    "            f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4,figsize=(15,5))\n",
    "            ax1.plot(t,mean,c='r',linewidth=3.0)\n",
    "            ax1.title.set_text('1. Normalized Peak')\n",
    "                \n",
    "            ax1.plot(t,chebfit, c='k',linestyle='--',linewidth=2.0)\n",
    "            ax1.set_xlabel(\"Time [ms]\")\n",
    "\n",
    "            ax2.title.set_text('2. Fitting Chebyshev polinomial')\n",
    "            ax2.plot(t,current_cheb,c='k',linewidth=3.0)\n",
    "            ax2.set_xlabel(\"Time [ms]\")\n",
    "            \n",
    "            ax3.plot(cheb.coef,c='k')\n",
    "            ax3.plot(npol, cheb.coef[-1], '.',c='k', ms=20)\n",
    "            ax3.title.set_text('3. Chebyshev coefficients')\n",
    "            ax3.set_xlabel('Coefficient #')\n",
    "            \n",
    "            ax4.axis('on')\n",
    "            ax4.plot(features,c='r',linewidth=3.0,alpha=0.5)\n",
    "            ax3.plot(features[:-1],c='r',linewidth=3.0,alpha=0.5)\n",
    "            ax4.title.set_text('4. Peak features')\n",
    "            ax4.set_xlabel('Feature #')\n",
    "            f.savefig('a%i.png'%npol)\n",
    "                \n",
    "            break\n",
    "        \n",
    "        # compute difference in feature vectors\n",
    "        cluster_errors = np.linalg.norm(c_feats - features, axis=1)\n",
    "        \n",
    "        if plot_steps == True:\n",
    "            #ax1.plot(mean,c='k',linestyle='--',zorder=3,label='new peak',linewidth=3.0)\n",
    "            #ax2.plot(features,c='k',linestyle='--',zorder=3,label='new peak',linewidth=3.0)\n",
    "            ax1.legend()\n",
    "            ax2.legend()\n",
    "\n",
    "        if np.min(cluster_errors) < error_threshold:\n",
    "            # assign eod to the class with the lowest cluster_error\n",
    "            labels[i] = clusters[np.argmin(cluster_errors)].label\n",
    "\n",
    "            #adapt this cluster with learning rate eta\n",
    "            #clusters[np.argmin(cluster_errors)].mean = (1-eta)*  \\\n",
    "            #clusters[np.argmin(cluster_errors)].mean +       \\\n",
    "            #    eta*mean[np.argmin(cluster_errors)]\n",
    "\n",
    "            clusters[np.argmin(cluster_errors)].features = (1-eta)*  \\\n",
    "                clusters[np.argmin(cluster_errors)].features +       \\\n",
    "                eta*features        \n",
    "\n",
    "            clusters[np.argmin(cluster_errors)].idxs[\n",
    "                (clusters[np.argmin(cluster_errors)\n",
    "                         ].idxs==0).argmax(axis=0)] = p_idx\n",
    "            \n",
    "            clusters[np.argmin(cluster_errors)].y[\n",
    "                (clusters[np.argmin(cluster_errors)\n",
    "                         ].y==0).argmax(axis=0)] = p_y\n",
    "            \n",
    "        else:\n",
    "            # check for collisions\n",
    "            # check out predicted next peak for all clusters\n",
    "            # if this predicted peak is in the current area\n",
    "            # for 2 or more cluster, assign this peak to all\n",
    "            # of those cluster.\n",
    "            idx_pred = np.zeros(len(clusters))\n",
    "            last_idx = np.zeros(len(clusters))\n",
    "            for c,cluster in enumerate(clusters):\n",
    "                idx_pred[c] = cluster.predict_next_idx()\n",
    "                last_idx[c] = np.max(cluster.idxs)\n",
    "            pred_error = np.abs(idx_pred - p_idx)\n",
    "            \n",
    "            if np.count_nonzero(pred_error<peakwidth*4) >= 2:\n",
    "                # assign this peak to both clusters but do not \n",
    "                # adapt the cluster features\n",
    "                labels[i] = -1\n",
    "                for j in np.nonzero(pred_error<peakwidth*4)[0]:\n",
    "                    clusters[j].idxs[\n",
    "                        (clusters[j].idxs==0).argmax(axis=0)] = p_idx\n",
    "                    clusters[j].y[\n",
    "                        (clusters[j].y==0).argmax(axis=0)] = p_y\n",
    "            \n",
    "            else:    \n",
    "                # create new cluster class\n",
    "                labels[i] = maxlabel\n",
    "\n",
    "                maxlabel = maxlabel + 1\n",
    "                new_cluster = cluster_object(labels[i],mean,\n",
    "                                         features,len(peaks))\n",
    "                new_cluster.idxs[0] = p_idx\n",
    "                new_cluster.y[0] = p_y\n",
    "\n",
    "                clusters.append(new_cluster)\n",
    "\n",
    "            if plot_means == True:\n",
    "                    ax1.plot(mean,c=colors[int(labels[i])])\n",
    "                    ax2.plot(features,c=colors[int(labels[i])])\n",
    "    else:\n",
    "        # create new cluster class\n",
    "        labels[i] = maxlabel\n",
    "        maxlabel = maxlabel + 1\n",
    "        \n",
    "        # take middle of snip\n",
    "        mid = int(len(eod_ip)/2)\n",
    "        eod_ip = extract(eod_ip,mid,alignwidth)\n",
    "        \n",
    "        # normalize\n",
    "        eod_ip = normalize(eod_ip)\n",
    "        \n",
    "        # set this as the standard peak for alignment\n",
    "        align_peak = eod_ip\n",
    "        \n",
    "        # extract features\n",
    "        cheb = np.polynomial.chebyshev.chebfit(np.linspace(-1,1,\n",
    "            len(eod_ip)), eod_ip, npol)\n",
    "        \n",
    "        #features = cheb.coef\n",
    "        features = np.append(cheb[:nfeat], p_hight/2)\n",
    "        #features = cheb\n",
    "        \n",
    "        new_cluster = cluster_object(labels[i],eod_ip,features,len(peaks))\n",
    "        new_cluster.idxs[0] = p_idx\n",
    "        new_cluster.y[0] = p_y\n",
    "        clusters.append(new_cluster)\n",
    "    \n",
    "    # save eods every n steps. before saving delete the short classes.\n",
    "    # save the peaks of the current buffered part to a numpy-memmap on the disk\n",
    "    # ==> sth like this: save_EOD_events_to_npmmp(thisblock_eods,eods_len,idx==startblock,datasavepath,mmpname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = np.append(np.transpose(peaks),[labels], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_ns = pt.discard_short_classes(peaks, 3)\n",
    "\n",
    "# set peaks that don't have many instances to the noise class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 30276)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peaks_ns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-279554f819cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolorss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "plt.axis(\"off\")\n",
    "for c in clusters:\n",
    "    if np.count_nonzero(c.idxs) > 10:\n",
    "        plt.plot(c.mean,c=colorss[int(c.label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in clusters:\n",
    "    if np.count_nonzero(c.idxs) > 10:\n",
    "        plt.plot(c.features,c=colors[int(c.label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "plt.plot(y,c='k',alpha=0.3)\n",
    "\n",
    "for cluster in clusters:\n",
    "    cx = cluster.idxs[np.nonzero(cluster.idxs)]\n",
    "    cy = cluster.y[np.nonzero(cluster.y)]\n",
    "    if len(cx) > 10:\n",
    "        plt.plot(cx,cy,'.',alpha=0.5,ms=20,label=cluster.label)\n",
    "    \n",
    "for cluster in deleted_clusters:\n",
    "    cx = cluster.idxs[np.nonzero(cluster.idxs)]\n",
    "    cy = cluster.y[np.nonzero(cluster.y)]\n",
    "    if len(cx) > 10:\n",
    "        plt.plot(cx,cy,'.',alpha=0.5,ms=20,label=cluster.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(peaks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
