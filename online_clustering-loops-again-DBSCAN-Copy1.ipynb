{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thunderfish.dataloader as dl\n",
    "import thunderfish.pulsetracker as pt\n",
    "import thunderfish.eventdetection as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters and functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peaks(x,y,peaksx,peaksy,c='k'):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(x,y,zorder=-1)\n",
    "    plt.scatter(starttime + peaksx/data.samplerate,peaksy,c=c)\n",
    "    plt.xlabel('time [s]')\n",
    "    plt.ylabel('signal')\n",
    "    \n",
    "def plot_events_on_data(peaks, data):\n",
    "    \n",
    "    \"\"\"\n",
    "        plots the detected events onto the data timeseries. If the events are classified, the classes are plotted in different colors and the class -1 (not belonging to a cluster) is plotted in black\n",
    "    \"\"\"\n",
    "    plt.plot(range(len(data)),data, color = 'black')\n",
    "    if len(peaks)>3:\n",
    "        classlist =  np.array(peaks[3],dtype=np.int)\n",
    "        if len(peaks) > 4:\n",
    "            classlist = np.array(peaks[4],dtype=np.int)\n",
    "        cmap = plt.get_cmap('jet')\n",
    "        colors =cmap(np.linspace(0, 1.0, 3000)) #len(np.unique(classlist))))\n",
    "        np.random.seed(3)\n",
    "        np.random.shuffle(colors)\n",
    "        colors = [colors[cl] for cl in np.unique(classlist)]\n",
    "        for cl, color in zip(np.unique(classlist), colors):\n",
    "            if min(classlist) == 0 and cl == 0:\n",
    "                color = 'black'\n",
    "            if cl == -1:\n",
    "                color = 'black'\n",
    "            \n",
    "            peaksofclass = peaks[:,classlist == cl]\n",
    "            plt.plot(peaksofclass[0],peaksofclass[1], '.', color = color,   ms =20, label=cl)\n",
    "    else:\n",
    "        plt.scatter(peaks[0],peaks[1], color = 'red')\n",
    "    #plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of filepaths..\n",
    "text_file = open(\"leticia_filenames_sorted.txt\", \"r\")\n",
    "lines = text_file.read().split('\\n')\n",
    "i = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/dexter/' + lines[i][:-4] + '/' + lines[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dexter/50926L08F13/50926L08F13.WAV'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = 0\n",
    "endtime = 100 #in seconds\n",
    "\n",
    "with dl.open_data(filepath, -1, 1.0) as data:\n",
    "    dt = 1/data.samplerate\n",
    "    # do something with the content of the file:\n",
    "    x = np.arange(starttime,endtime,dt)\n",
    "    y = data[starttime*data.samplerate:endtime*data.samplerate,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# online clustering step by step\n",
    "## 1. EOD detection\n",
    "Create a data structures with the locations and amplitudes of the EODs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import correlate\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# parameters for the analysis\n",
    "thresh = 0.1 # minimal threshold for peakdetection\n",
    "peakwidth = 20 # width of a peak and minimal distance between two EODs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk, tr = ed.detect_peaks(y, thresh)\n",
    "peaks = pt.makeeventlist(pk,tr,y,peakwidth)\n",
    "peakindices, peakx, peakh = pt.discardnearbyevents(peaks[0],peaks[1],peakwidth)\n",
    "peaks = np.transpose(peaks[:,peakindices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Online clustering\n",
    "create object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cluster_object(object):\n",
    "    \n",
    "    def __init__(self,label,mean,peaknum,featnum,track_lenght):\n",
    "        self.label = label\n",
    "        self.mean = mean\n",
    "        self.track_length = track_length\n",
    "        \n",
    "        # this should be a numpy array with at least 100 peaks?\n",
    "        self.features = np.zeros((track_length,featnum))\n",
    "        \n",
    "        self.idxs = np.zeros(peaknum)\n",
    "        self.y = np.zeros(peaknum)\n",
    "        \n",
    "        self.peak_count = 0\n",
    "    \n",
    "    def update(self,x,y,features):\n",
    "        \n",
    "        self.idxs[self.peak_count] = x\n",
    "        self.y[self.peak_count] = y\n",
    "        self.features[int(self.peak_count%track_length)] = features\n",
    "        \n",
    "        self.peak_count = self.peak_count + 1\n",
    "        \n",
    "    def predict_next_idx(self):\n",
    "        return np.max(self.idxs) + self.get_isi()\n",
    "    \n",
    "    def get_isi(self):\n",
    "        return np.mean(np.diff(self.idxs[self.peak_count-4:self.peak_count]))\n",
    "\n",
    "def merge_clusters(cluster1,cluster2,track_length):\n",
    "    \n",
    "    merged_cluster = cluster_object(cluster1.label,cluster1.mean,len(cluster1.y),cluster1.features.shape[1],cluster1.features.shape[0])\n",
    "    \n",
    "    merged_idx = np.append(cluster1.idxs[np.nonzero(cluster1.idxs)],cluster2.idxs[np.nonzero(cluster2.idxs)])\n",
    "    merged_y = np.append(cluster1.y[np.nonzero(cluster1.y)],cluster2.y[np.nonzero(cluster2.y)])\n",
    "    \n",
    "    merged_cluster.idxs[:len(merged_idx)] = merged_idx\n",
    "    merged_cluster.y[:len(merged_y)] = merged_y\n",
    "\n",
    "    cur_idx = cluster1.peak_count % track_length\n",
    "    last_half = range(cur_idx-int(track_length/2), cur_idx)\n",
    "    \n",
    "    # take last 50 features of cluster1\n",
    "    for i in range(cluster1.features.shape[1]):\n",
    "        merged_cluster.features[:int(track_length/2),i] = cluster1.features[:,i].take(last_half, mode='wrap')\n",
    "        merged_cluster.features[int(track_length/2):,i] = cluster2.features[:,i].take(last_half, mode='wrap')\n",
    "    \n",
    "    merged_cluster.peak_count = len(merged_y)\n",
    "    \n",
    "    return merged_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(eod,cluster_mean,width):\n",
    "    \n",
    "    # don't just take max but take a peak of the cc\n",
    "    # this is to prevent shifting to the next peak in the sequence.\n",
    "    \n",
    "    cc = correlate(eod,cluster_mean,'same')\n",
    "    local_max_idx = argrelextrema(cc[width:-width], np.greater)[0] + width\n",
    "    diff = np.abs(local_max_idx - len(eod)/2)\n",
    "    \n",
    "    if diff.size > 0:\n",
    "        #offset = local_max_idx[np.argmin(diff)]\n",
    "        offset = local_max_idx[np.argmax(cc[local_max_idx])]\n",
    "    else:\n",
    "        offset = int(len(eod)/2)\n",
    "    return extract(eod,offset,width)\n",
    "    \n",
    "def extract(eod,offset,width):\n",
    "    return eod[offset-width:offset+width]\n",
    "\n",
    "def normalize(x):\n",
    "    #return x - np.min(x)\n",
    "    return (((x-np.min(x))/(np.max(x)-np.min(x))) - 0.5)*2\n",
    "\n",
    "def gen_cheb(n,x):\n",
    "    return(np.cos(n*np.arccos(x)))\n",
    "\n",
    "def find_min_idx(x):\n",
    "    k = x.argmin()\n",
    "    ncol = x.shape[1]\n",
    "    return k/ncol, k%ncol\n",
    "\n",
    "cmap = plt.get_cmap('jet')\n",
    "colors = cmap(np.linspace(0, 1.0, 3000)) #len(np.unique(classlist))))\n",
    "np.random.seed(4)\n",
    "np.random.shuffle(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:133: RuntimeWarning: invalid value encountered in less\n",
      "/home/liz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:135: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "clusters = []\n",
    "deleted_clusters = []\n",
    "\n",
    "maxlabel = 1\n",
    "\n",
    "# parameters\n",
    "cutwidth = peakwidth*2\n",
    "alignwidth = 150\n",
    "int_met = 'quadratic'\n",
    "error_threshold = 0.04 #different thresholds are needed for different problems\n",
    "merge_threshold = 0.04\n",
    "npol = 15\n",
    "nfeat = 7\n",
    "\n",
    "track_length = 100\n",
    "\n",
    "#decide on the plotting\n",
    "plot_steps = False\n",
    "plot_means = False\n",
    "plot_one_peak_step = False\n",
    "\n",
    "if plot_means == True:\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2,figsize=(10,5))\n",
    "\n",
    "for i,p in enumerate(peaks):\n",
    "    \n",
    "    if plot_steps == True:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2,figsize=(10,5))\n",
    "        #f, ax1 = plt.subplots(1, 1,figsize=(5,5))\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.axis(\"off\")\n",
    "    \n",
    "    # cut along peak to get the EOD shape\n",
    "    p_idx = int(p[0])\n",
    "    p_hight = p[2]\n",
    "    p_y = p[1]\n",
    "    \n",
    "    eod = y[p_idx-cutwidth:p_idx+cutwidth]\n",
    "    \n",
    "    #interpolate --> needed to properly align peaks\n",
    "    eod_func = interp1d(range(len(eod)), eod, int_met)\n",
    "    eod_ip = eod_func(np.arange(0,len(eod)-1,0.1))\n",
    "    \n",
    "    # align peaks with aligning peak\n",
    "    if len(clusters) > 0:\n",
    "        \n",
    "        current_clusters = []\n",
    "        \n",
    "        # I only want to use recent clusters, \n",
    "        # but somehow I also need to save all clusters for later\n",
    "        for c, cluster in enumerate(clusters):\n",
    "            # delete clusters that are too far away\n",
    "            if p_idx - np.max(cluster.idxs) < 2000000: #and np.count_nonzero(labels == cluster.label) < 3:\n",
    "                current_clusters.append(cluster)\n",
    "            else:\n",
    "                deleted_clusters.append(cluster)\n",
    "                \n",
    "        clusters = current_clusters\n",
    " \n",
    "        c_feats = np.zeros((len(clusters),track_length,nfeat))\n",
    "        \n",
    "        # ============== start analysis =================\n",
    "        \n",
    "        ## allocate space\n",
    "        aligned_eods = np.zeros((len(clusters),alignwidth*2))\n",
    "        \n",
    "        for c,cluster in enumerate(clusters):\n",
    "            c_feats[c] = cluster.features\n",
    "        \n",
    "            aligned_eods[c] = align(eod_ip, cluster.mean, alignwidth)\n",
    "            \n",
    "            if plot_steps == True:\n",
    "                ax1.plot(cluster.mean)\n",
    "                ax1.plot(np.transpose(aligned_eods),c='k',alpha=0.5)\n",
    "                ax1.title.set_text('Normalized EODs')\n",
    "                #ax2.plot(cluster.features[0],c=colors[int(cluster.label)],label='fish %i'%cluster.label,linewidth=3.0)\n",
    "                #ax2.title.set_text('Features')\n",
    "        \n",
    "        # normalize\n",
    "        means = normalize(aligned_eods)\n",
    "        \n",
    "        # extract features\n",
    "        chebs = np.polynomial.chebyshev.chebfit(np.linspace(-1,1,\n",
    "            means.shape[1]), np.transpose(means), npol)\n",
    "\n",
    "        \n",
    "        # append peak hight to features\n",
    "        features = np.transpose(np.vstack((chebs[:nfeat-1], np.ones(len(clusters))*p_hight/2)))\n",
    "        \n",
    "        # compute difference in feature vectors\n",
    "        cluster_errors = np.linalg.norm(np.transpose(c_feats,(1,0,2)) - features, axis=2)\n",
    "\n",
    "        # take min for each cluster\n",
    "        cluster_errors = np.min(cluster_errors, axis=0)\n",
    "\n",
    "        #if plot_steps == True:\n",
    "        #    ax1.plot(mean,c='k')\n",
    "        #    ax2.plot(features,c='k')\n",
    "        #    ax2.title.set_text('Features')\n",
    "        \n",
    "        if np.min(cluster_errors) < error_threshold:\n",
    "            # check if two clusters can be merged\n",
    "            merge_idx = np.where(cluster_errors < merge_threshold)[0]\n",
    "            if len(merge_idx) > 1:\n",
    "                # merge clusters\n",
    "                cluster_merged = merge_clusters(clusters[merge_idx[0]],\n",
    "                                                clusters[merge_idx[1]],\n",
    "                                               track_length)\n",
    "                # delete old clusters\n",
    "                clusters.pop(merge_idx[1])\n",
    "                clusters.pop(merge_idx[0])\n",
    "                cluster_merged.update(p_idx,p_y,features[merge_idx[0]])\n",
    "                clusters.append(cluster_merged)\n",
    "            else:\n",
    "                closest_cluster = cluster_errors.argmin()\n",
    "                clusters[closest_cluster].update(p_idx,p_y,features[closest_cluster])\n",
    "            # assign eod to the class with the lowest cluster_error\n",
    "\n",
    "        else:\n",
    "            # check for collisions\n",
    "            # check out predicted next peak for all clusters\n",
    "            # if this predicted peak is in the current area\n",
    "            # for 2 or more cluster, assign this peak to all\n",
    "            # of those cluster.\n",
    "            \n",
    "            idx_pred = np.zeros(len(clusters))\n",
    "            \n",
    "            for c,cluster in enumerate(clusters):\n",
    "                idx_pred[c] = cluster.predict_next_idx()\n",
    "                \n",
    "            pred_error = np.abs(idx_pred - p_idx)\n",
    "            \n",
    "            if np.count_nonzero(pred_error<peakwidth*4) >= 2:\n",
    "                # assign this peak to both clusters but do not update features\n",
    "                for j in np.nonzero(pred_error<peakwidth*4)[0]:\n",
    "                    clusters[j].update(p_idx,p_y,np.zeros(nfeat))\n",
    "                    \n",
    "            else:    \n",
    "                new_cluster = cluster_object(maxlabel,means[cluster_errors.argmin()],len(peaks),nfeat,track_length)\n",
    "                if plot_means == True:\n",
    "                    ax1.plot(mean,c=colors[int(maxlabel)])\n",
    "                    ax2.plot(features,c=colors[int(maxlabel)])\n",
    "                \n",
    "                maxlabel = maxlabel + 1\n",
    "                \n",
    "                new_cluster.update(p_idx,p_y,features[cluster_errors.argmin()])\n",
    "\n",
    "                clusters.append(new_cluster)\n",
    "\n",
    "    else:\n",
    "        # create new cluster class\n",
    "        \n",
    "        # take middle of snip\n",
    "        mid = int(len(eod_ip)/2)\n",
    "        eod_ip = extract(eod_ip,mid,alignwidth)\n",
    "        \n",
    "        # normalize\n",
    "        eod_ip = normalize(eod_ip)\n",
    "        \n",
    "        # set this as the standard peak for alignment\n",
    "        align_peak = eod_ip\n",
    "        \n",
    "        # extract features\n",
    "        cheb = np.polynomial.chebyshev.chebfit(np.linspace(-1,1,\n",
    "            len(eod_ip)), eod_ip, npol)\n",
    "        \n",
    "        #features = cheb.coef\n",
    "        features = np.append(cheb[:nfeat-1], p_hight/2)\n",
    "        \n",
    "        new_cluster = cluster_object(maxlabel,eod_ip,len(peaks),nfeat,track_length)\n",
    "        new_cluster.update(p_idx, p_y, features)\n",
    "        maxlabel = maxlabel + 1\n",
    "        \n",
    "        clusters.append(new_cluster)\n",
    "    \n",
    "    # save eods every n steps. before saving delete the short classes.\n",
    "    # save the peaks of the current buffered part to a numpy-memmap on the disk\n",
    "    # ==> sth like this: save_EOD_events_to_npmmp(thisblock_eods,eods_len,idx==startblock,datasavepath,mmpname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('jet')\n",
    "colors = cmap(np.linspace(0, 1.0, 4)) #len(np.unique(classlist))))\n",
    "np.random.seed(4)\n",
    "np.random.shuffle(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e138f495e800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "h = 0\n",
    "plt.axis(\"off\")\n",
    "for i,c in enumerate(clusters):\n",
    "    if np.count_nonzero(c.idxs) > 10:\n",
    "        plt.plot(c.mean,c=colors[h+1],linewidth=3)\n",
    "        print(h)\n",
    "        h = h + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "for i,c in enumerate(clusters):\n",
    "    if np.count_nonzero(c.idxs) > 10:\n",
    "        plt.plot(np.transpose(c.features),c=colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('jet')\n",
    "colors = cmap(np.linspace(0, 1.0, 5)) #len(np.unique(classlist))))\n",
    "np.random.seed(4)\n",
    "np.random.shuffle(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4d0c01292ced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#for cluster in deleted_clusters:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "plt.plot(y,c='k')\n",
    "#plt.axis(\"off\")\n",
    "h = 0\n",
    "for l,cluster in enumerate(clusters):\n",
    "    cx = cluster.idxs[np.nonzero(cluster.idxs)]\n",
    "    cy = cluster.y[np.nonzero(cluster.y)]\n",
    "    if len(cx) > 10:\n",
    "        plt.plot(cx,cy,'.',c=colors[h+1],ms=20,label=cluster.label)\n",
    "        h = h + 1\n",
    "#for cluster in deleted_clusters:\n",
    "#    cx = cluster.idxs[np.nonzero(cluster.idxs)]\n",
    "#    cy = cluster.y[np.nonzero(cluster.y)]\n",
    "#    if len(cx) > 10:\n",
    "#        plt.plot(cx,cy,'.',alpha=0.5,ms=20,label=cluster.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(peaks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
